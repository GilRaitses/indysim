\documentclass[aspectratio=169,11pt]{beamer}
\usetheme{metropolis}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{fontspec}

% Set Didot font for footer page numbers
\newfontfamily\didotfont{Didot}

% Reduce bottom margin for captions
\setbeamertemplate{frametitle}[default][left]
\addtobeamertemplate{frametitle}{}{\vspace{-0.3em}}

% Add centered page numbers in Didot font
\setbeamertemplate{footline}{%
  \hfill\usebeamercolor[fg]{page number in head/foot}%
  {\didotfont\insertframenumber}\hfill\vskip2pt%
}

\title{Sensorimotor Habituation in \textit{Drosophila} Larvae}
\subtitle{Population-Level Modeling and Individual Phenotyping Validation}
\author{Gil Raitses}
\institute{Syracuse University}
\date{Bhattacharya Lab General Meeting}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

%% ===========================================
%% PART 1: ORIGINAL STUDY
%% ===========================================

\begin{frame}{Original Study Overview}
\textbf{Population-Level Sensorimotor Habituation Model}

\vspace{0.3cm}
Larval reorientation behavior follows a gamma-difference kernel with two distinct timescales that capture the dynamics of sensory response and adaptation.

\vspace{0.3cm}
The fast excitatory component with $\tau_1 \approx 0.3$ seconds drives the initial response to optogenetic light onset. The slow inhibitory component with $\tau_2 \approx 4$ seconds produces delayed suppression that underlies behavioral habituation across repeated stimuli.

\vspace{0.3cm}
The model was validated across 14 experiments comprising 701 unique larval tracks collected under four stimulation conditions.

\vspace{0.4cm}
\textbf{Key Result} \quad The gamma-difference kernel accurately predicts population-level reorientation dynamics and provides biologically interpretable timescales.
\end{frame}

\begin{frame}{Kernel Structure}
\centering
\includegraphics[height=0.68\textheight]{../../figures/figure1_kernel.png}

\vspace{0.15cm}
\small The gamma-difference kernel $K(t) = A \cdot \Gamma(t;\alpha_1,\beta_1) - B \cdot \Gamma(t;\alpha_2,\beta_2)$ modulates reorientation hazard rate following LED onset. The left panel shows the combined kernel with peak excitation at 0.3 seconds followed by suppression reaching minimum at 3 seconds. The right panel decomposes this into fast excitatory gamma in green with $\tau_1 = 0.29$s and slow suppressive gamma in red with $\tau_2 = 3.81$s.
\end{frame}

\begin{frame}{PSTH Computation Methods}
\textbf{Empirical vs Parametric Approaches}

\vspace{0.3cm}
\textbf{Empirical PSTH} \quad The peri-stimulus time histogram bins event times relative to LED onset into 100ms intervals. Each bin contains the fraction of events occurring at that latency across all trials. The empirical PSTH is computed directly from data using histogram binning without assuming any functional form.

\vspace{0.3cm}
\textbf{Parametric PSTH} \quad The Bernoulli event probability is derived from the fitted kernel. At each timestep, event probability $p(t) = 1 - \exp(-\lambda(t) \cdot \Delta t)$ where $\lambda(t) = \lambda_0 \exp(K(t))$ is the hazard rate modulated by kernel $K(t)$. The parametric PSTH evaluates this probability function at each time point.

\vspace{0.3cm}
\textbf{Model Fitting} \quad The kernel is fitted by maximizing the likelihood that empirical event times arise from the Bernoulli process. The empirical PSTH is used for visualization and validation. The parametric model enables prediction and simulation.
\end{frame}

\begin{frame}{Simulation Track Generation}
\textbf{Bernoulli Point Process Framework}

\vspace{0.3cm}
Simulated tracks are generated using the fitted population kernel as follows.

\vspace{0.2cm}
\textbf{Step 1} \quad For each timestep $\Delta t = 0.1$s, compute the hazard rate $\lambda(t) = \lambda_0 \exp(K(t) + \eta_{\text{track}})$ where $\eta_{\text{track}} \sim \mathcal{N}(0, \sigma^2)$ is track-specific random intercept.

\vspace{0.2cm}
\textbf{Step 2} \quad Convert hazard to event probability $p(t) = 1 - \exp(-\lambda(t) \cdot \Delta t)$.

\vspace{0.2cm}
\textbf{Step 3} \quad Draw Bernoulli sample $E(t) \sim \text{Bernoulli}(p(t))$ for each timestep.

\vspace{0.2cm}
\textbf{Step 4} \quad Impose 2-second refractory period after each event.

\vspace{0.3cm}
The baseline intercept and track-level variability $\sigma$ determine mean event rate and across-track variance.
\end{frame}

\begin{frame}{Parameter Sweep for Simulation Calibration}
\textbf{Optimizing Simulation to Match Empirical Data}

\vspace{0.3cm}
A grid search over simulation parameters found the combination that best matches empirical event count distributions.

\vspace{0.3cm}
\textbf{Parameters swept}
\begin{itemize}
\item Baseline intercept: $-7.0$ to $-6.0$ in steps of $0.02$
\item Track intercept standard deviation: $0.1$ to $0.8$ in steps of $0.02$
\end{itemize}

\vspace{0.3cm}
\textbf{Optimal values found}
\begin{itemize}
\item Intercept $= -6.54$ produces mean 14.9 events per 10-minute track
\item Track std $\sigma = 0.38$ produces realistic across-track variance
\end{itemize}

\vspace{0.3cm}
\textbf{Validation} \quad Simulated event count distribution with optimized parameters matches empirical distribution with KS test p $> 0.05$.
\end{frame}

\begin{frame}{Simulated vs Empirical Event Counts}
\centering
\includegraphics[height=0.68\textheight]{../figures/fig_simulation_design.pdf}

\vspace{0.15cm}
\small Validation of the simulation model against empirical data. Panel A shows overlapping histograms of event counts per track for 260 empirical tracks in cyan and 300 simulated tracks in pink. Panel B shows box plots comparing the distributions. The simulated tracks were generated using the fitted population kernel with intercept $= -6.54$ and track std $= 0.38$ and match the empirical distribution with median 15 events per track.
\end{frame}

\begin{frame}{Habituation Dynamics}
\centering
\includegraphics[height=0.65\textheight]{../../figures/figure_habituation.png}

\vspace{0.15cm}
\small Fraction of time spent turning increases across successive LED pulses in all four experimental conditions. Orange and green lines show 0-250 PWM conditions while pink and purple show 50-250 PWM conditions. Steeper slopes indicate faster habituation. The 0-250 Cycling condition shows the strongest habituation effect with slope +0.031 per pulse. Shaded bands indicate 95\% confidence intervals. Asterisks mark pulses significantly different from pulse 0.
\end{frame}

\begin{frame}{Behavioral State Analysis}
\centering
\includegraphics[height=0.65\textheight]{figures/figure_behavior_stacked_cinnamoroll.png}

\vspace{0.15cm}
\small Fractional behavioral state usage across LED pulses for all four experimental conditions. Gray indicates forward running. Pink indicates turning behavior. Blue indicates pausing. Orange indicates reverse crawling. Turning fraction increases dramatically across pulses in all conditions while running fraction decreases. Pausing remains below 5\% throughout. The 50-250 Cycling condition shows the largest shift from running to turning behavior by pulse 17.
\end{frame}

\begin{frame}{Leave-One-Experiment-Out Validation}
\centering
\includegraphics[height=0.65\textheight]{../../figures/loeo_permutation_null.png}

\vspace{0.15cm}
\small LOEO cross-validation assesses whether kernel parameters generalize across experiments. The histogram shows the null distribution generated from 1000 permutations of experiment labels. The observed pass rate of 50\% falls within the null distribution with p=0.618 indicating that cross-experiment generalization is no better than chance. Model performs reliably at the population level but individual experiments show high variability.
\end{frame}

%% ===========================================
%% PART 2: FOLLOW-UP STUDY
%% ===========================================

\begin{frame}{Follow-Up Study Overview}
\textbf{Individual-Level Phenotyping Validation}

\vspace{0.3cm}
The follow-up study asked whether individual larvae can be phenotyped using kernel parameters. The answer is negative with current protocols.

\vspace{0.3cm}
\textbf{Challenge} \quad Sparse data with only 18 to 25 events per 10 to 20 minute track makes 6-parameter kernel estimation unreliable.

\vspace{0.3cm}
\textbf{Finding} \quad Apparent phenotypic clusters identified by K-means are statistical artifacts of sparse data. Gap statistic optimization suggests k=1 is optimal indicating no discrete phenotypes exist.

\vspace{0.3cm}
Only 8.6\% of tracks show genuine individual differences that exceed measurement noise.

\vspace{0.3cm}
\textbf{Key Result} \quad Individual-level phenotyping requires experimental protocol modifications before reliable kernel-based phenotyping becomes feasible.
\end{frame}

%% Clustering Illusion - Use ORIGINAL multi-panel figure (Dec 21 12:52)
\begin{frame}{The Clustering Illusion}
\centering
\includegraphics[height=0.72\textheight]{../figures/core/fig1_clustering_illusion.pdf}

\vspace{0.1cm}
\small Panel A shows true PCA distribution revealing unimodal structure with some outliers. Panel B shows all four validation methods failed with ARI below 0.13. Panel C shows gap statistic is minimized at k=1 indicating no discrete clusters exist.
\end{frame}

%% Data Sparsity - Use ORIGINAL multi-panel figure (Dec 21 12:52)
\begin{frame}{Data Sparsity Explains Instability}
\centering
\includegraphics[height=0.72\textheight]{../figures/core/fig2_data_sparsity.pdf}

\vspace{0.1cm}
\small Panel A shows mean 25 events per track versus the 100 required for stable estimation. Panel B shows many MLE estimates fall in the implausible range above 1.5 seconds. Panel C shows the math problem: 4 parameters divided by 25 events equals a 6:1 ratio which is underdetermined.
\end{frame}

%% Hierarchical Shrinkage - Use ORIGINAL multi-panel figure (Dec 21 12:52)
\begin{frame}{Hierarchical Shrinkage}
\centering
\includegraphics[height=0.72\textheight]{../figures/core/fig3_hierarchical_shrinkage.pdf}

\vspace{0.1cm}
\small Bayesian estimates shrink toward population mean proportionally to data sparsity. Tracks with extreme MLE values show the most shrinkage while tracks with abundant data retain individual estimates.
\end{frame}

%% Identifiability - Use ORIGINAL multi-panel figure (Dec 21 12:52)
\begin{frame}{The Identifiability Problem}
\centering
\includegraphics[height=0.72\textheight]{../figures/fig2_identifiability_v3.pdf}

\vspace{0.1cm}
\small Panel A shows continuous design produces high bias and RMSE. Panel B shows burst design extracts 10x more Fisher Information. Panel C shows MLE recovery differs by design. Panel D explains why continuous fails: inhibition dominates.
\end{frame}

%% Stimulation Protocols - Use ORIGINAL multi-panel figure (Dec 21 12:52)
\begin{frame}{Stimulation Protocol Comparison}
\centering
\includegraphics[height=0.72\textheight]{../figures/fig_stimulation_schematic.pdf}

\vspace{0.1cm}
\small Four LED stimulation designs showing the 30-second cycle structure. Panel A shows current continuous 10s design with low power. Panel B shows recommended burst 10x0.5s with 8x more information. Panels C and D show intermediate alternatives.
\end{frame}

%% Kernel Comparison - Use ORIGINAL figure (Dec 21 12:52)
\begin{frame}{Kernel Model Comparison}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig7_model_comparison.pdf}

\vspace{0.15cm}
\small Model comparison shows the gamma-difference kernel achieves R$^2$ = 0.968 with 6 parameters. The raised cosine basis achieves R$^2$ = 0.974 but requires 12 parameters. The gamma-difference form provides biological interpretability with equivalent fit quality.
\end{frame}

%% ===========================================
%% RECOMMENDATIONS - 5 SLIDES WITH FIGURES
%% ===========================================

\begin{frame}{Protocol Modification}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig4_recommendations_v2.pdf}

\vspace{0.15cm}
\small Replace continuous 10-second ON periods with burst trains. Burst design samples the early excitatory window where $\tau_1$ is identifiable. Each burst event carries 10 times more Fisher information than continuous events. This modification alone could reduce the number of events required for reliable estimation from 100 to 30.
\end{frame}

\begin{frame}{Extended Recording}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig5_power_analysis.pdf}

\vspace{0.15cm}
\small Target 40 minutes or more of recording to achieve at least 50 reorientation events per track. Current 10 to 20 minute recordings yield only 18 to 25 events which is insufficient for 6-parameter estimation. Power analysis indicates that 100 events are required for 80\% power to detect a 0.2 second difference in $\tau_1$ at the individual level.
\end{frame}

\begin{frame}{Model Simplification}
\centering
\includegraphics[height=0.65\textheight]{../figures/core/fig3_hierarchical_shrinkage.pdf}

\vspace{0.15cm}
\small Reduce the parameter space by fixing population-derived parameters. Fix $\tau_2$ at the population estimate of 3.8 seconds and fix the amplitude ratio B/A at the population value of 8. Estimate only the fast timescale $\tau_1$ per individual track. Hierarchical Bayesian estimation provides natural regularization toward the population mean.
\end{frame}

\begin{frame}{Alternative Phenotypes}
\centering
\includegraphics[height=0.65\textheight]{../figures/core/fig4_fast_responders.pdf}

\vspace{0.15cm}
\small Use robust composite phenotypes that avoid kernel fitting entirely. The ON/OFF event ratio measures whether larvae respond preferentially during LED-ON versus LED-OFF periods and requires only event counts not full kernel estimation. First-event latency measures the time from LED onset to first reorientation and captures response speed directly.
\end{frame}

\begin{frame}{Within-Condition Analysis}
\centering
\includegraphics[height=0.65\textheight]{../figures/core/fig1_clustering_illusion.pdf}

\vspace{0.15cm}
\small Analyze individual differences within experimental conditions rather than pooling across conditions. When data from different stimulation intensities and temporal patterns are pooled the condition effects dominate and mask genuine individual variation. The ARI near zero across all validation methods indicates no reproducible structure when pooling.
\end{frame}

%% ===========================================
%% CONCLUSIONS
%% ===========================================

\begin{frame}{Original Study Summary}
\textbf{Population-Level Modeling Success}

\vspace{0.3cm}
The gamma-difference kernel accurately models population-level reorientation dynamics across 14 experiments and 701 unique larval tracks.

\vspace{0.3cm}
Two timescales govern behavioral dynamics. Fast excitation with $\tau_1 \approx 0.3$ seconds captures the initial sensory response to optogenetic stimulation. Slow suppression with $\tau_2 \approx 4$ seconds captures habituation-like adaptation that accumulates across repeated stimuli.

\vspace{0.3cm}
The model is robust across experimental conditions as demonstrated by leave-one-experiment-out cross-validation and bootstrap confidence intervals.

\vspace{0.3cm}
The gamma-difference form provides biological interpretability that flexible basis function models lack while achieving equivalent goodness of fit.
\end{frame}

\begin{frame}{Follow-Up Study Summary}
\textbf{Individual Phenotyping Challenges}

\vspace{0.3cm}
Individual phenotyping using kernel parameters fails with current experimental protocols due to fundamentally sparse data.

\vspace{0.3cm}
Apparent clusters identified by K-means or hierarchical clustering are statistical artifacts of fitting high-dimensional models to low-event tracks rather than genuine discrete phenotypes.

\vspace{0.3cm}
Only 8.6\% of tracks show individual variation that exceeds the measurement noise floor.

\vspace{0.3cm}
Current protocols achieve only 20 to 30\% statistical power for detecting fast responder phenotypes.

\vspace{0.4cm}
\textbf{Bottom Line} \quad Population-level analysis is robust and biologically meaningful. Individual phenotyping requires experimental redesign before kernel-based classification becomes reliable.
\end{frame}

\begin{frame}
\centering
\Huge Thank You

\vspace{1cm}
\Large Questions?
\end{frame}

%% ===========================================
%% FAQ SECTION
%% ===========================================

\begin{frame}{Original Study Methods}
\textbf{What is the sequence of processes in the original study?}

\vspace{0.3cm}
\textbf{Data collection} \quad 14 optogenetic experiments with 701 larval tracks under four stimulation conditions varying intensity from 0-250 PWM versus 50-250 PWM and temporal pattern from constant versus cycling.

\vspace{0.2cm}
\textbf{Trajectory extraction} \quad MAGAT Analyzer extracts larval trajectories from video and segments behavioral states including runs and reorientations.

\vspace{0.2cm}
\textbf{Event detection} \quad Reorientation onset times are extracted from MAGAT segmentation as point events for hazard modeling.

\vspace{0.2cm}
\textbf{Kernel fitting} \quad Population-level gamma-difference kernel is fitted using maximum likelihood estimation on the pooled PSTH.

\vspace{0.2cm}
\textbf{Validation} \quad Leave-one-experiment-out cross-validation and bootstrap confidence intervals assess generalization and parameter uncertainty.
\end{frame}

\begin{frame}{Follow-Up Study Methods}
\textbf{What processes were used in the follow-up study?}

\vspace{0.3cm}
\textbf{Individual fitting} \quad Maximum likelihood estimation of 6-parameter gamma-difference kernel per track using the same event data.

\vspace{0.2cm}
\textbf{Clustering} \quad K-means and hierarchical clustering applied to individual kernel parameters to identify putative phenotypic groups.

\vspace{0.2cm}
\textbf{Validation} \quad Round-trip validation simulates from fitted kernels and re-clusters to test reproducibility. Gap statistic tests whether k clusters improve over k=1.

\vspace{0.2cm}
\textbf{Power analysis} \quad Simulation-based analysis estimates statistical power for phenotype detection as a function of event count and protocol design.

\vspace{0.2cm}
\textbf{Identifiability analysis} \quad Fisher Information quantifies how much information each event contains about kernel parameters under different stimulation designs.
\end{frame}

\begin{frame}{Why Population Modeling Succeeds}
\textbf{The key is the data-to-parameter ratio}

\vspace{0.3cm}
Population modeling pools approximately 15,000 reorientation events across 701 tracks to estimate 6 kernel parameters. The data-to-parameter ratio exceeds 2,500 to 1 providing strong statistical power.

\vspace{0.3cm}
Individual modeling attempts to estimate the same 6 parameters from only 18 to 25 events per track. The data-to-parameter ratio is only 3 to 5 which is far below the minimum of 10 to 1 needed for reliable maximum likelihood estimation.

\vspace{0.3cm}
The gamma-difference kernel is overparameterized for individual-level sparse data. Identifiability analysis reveals that only $\tau_1$ and possibly the amplitude ratio can be reliably estimated with fewer than 50 events.

\vspace{0.3cm}
Hierarchical Bayesian estimation provides partial mitigation by shrinking individual estimates toward the population mean but cannot create information that is not present in the data.
\end{frame}

\begin{frame}{Hierarchical Shrinkage Explained}
\textbf{Regularization through shared population structure}

\vspace{0.3cm}
Hierarchical Bayesian models assume individual parameters are drawn from a population distribution with unknown mean and variance.

\vspace{0.3cm}
Tracks with sparse data are shrunk toward the population mean because their individual estimates are uncertain. Tracks with abundant data retain individual estimates because they contain sufficient information.

\vspace{0.3cm}
The amount of shrinkage is determined automatically by the posterior distribution. More sparse data produces more shrinkage.

\vspace{0.3cm}
Shrinkage is not a bias correction. It is optimal regularization under the assumption that individuals are exchangeable members of a population.

\vspace{0.3cm}
In the data sparsity regime of this study almost all individual estimates are shrunk heavily toward the population mean confirming that individual phenotyping is not feasible without protocol changes.
\end{frame}

\begin{frame}{Interpreting Clustering Results}
\textbf{Clusters in sparse high-dimensional data are usually artifacts}

\vspace{0.3cm}
K-means and hierarchical clustering will always produce k clusters regardless of whether true clusters exist in the data.

\vspace{0.3cm}
The gap statistic compares within-cluster dispersion to a null reference and finds that k=1 is optimal meaning no discrete clusters are present.

\vspace{0.3cm}
Round-trip validation tests whether clusters are reproducible by simulating new data from fitted parameters and re-clustering. Agreement below ARI = 0.2 indicates clusters are not reproducible.

\vspace{0.3cm}
The continuous unimodal PCA distribution confirms that kernel parameter variation is smooth rather than discrete.

\vspace{0.3cm}
Future clustering should be attempted only after protocol modifications increase event counts to 100 or more per track and reduce the parameter space to 1 or 2 dimensions.
\end{frame}

\begin{frame}{Data Structures and Extraction Methods}
\textbf{MAGAT Analyzer}

Marc Gershow's MAGAT Analyzer extracts larval trajectories from video and segments behavioral states. The segmentation identifies runs, reorientations, and head swings based on heading angle changes and movement patterns. Reorientation onset events are detected as transitions from RUN to TURN state. These discrete events serve as the dependent variable for hazard modeling.

\vspace{0.3cm}
\textbf{Run Tables}

Run tables structure run-level statistics using reorientation events as boundaries. Each row represents a forward movement period between two reorientations. Fields include run duration, run distance, mean speed, heading change, and LED state at run start. Mason Klein developed the run table methodology for organizing behavioral segments into analyzable units.

\vspace{0.3cm}
\textbf{Events Group}

The events group records reorientation start events detected by MAGAT segmentation. Each row is a discrete reorientation onset with timestamp, position, LED state, and preceding run statistics. The events group contains 7,867 reorientations across 414 tracks while the run table contains 8,822 runs across 424 tracks. The difference arises because run tables count all runs including final runs that may not end in reorientations.

\vspace{0.3cm}
\textbf{Usage} \quad Kernel fitting uses the events group because it directly counts reorientation events. Run tables provide complementary run-level statistics for quality filtering and behavioral characterization.
\end{frame}

\begin{frame}{From Counting to Simulation}
\textbf{Traditional Methods}

Behavioral analysis typically relies on counting events, computing heatmaps, and visualizing discretized event histograms. These descriptive statistics summarize what happened but cannot predict what will happen under new conditions.

\vspace{0.3cm}
\textbf{What Simulation Modeling Extends}

The kernel-based hazard model converts descriptive counts into a generative process. Given LED timing and kernel parameters, the model predicts event probabilities at every timestep. Simulation generates synthetic trajectories that can be compared against empirical data to validate the model and test hypotheses before running experiments.

\vspace{0.3cm}
\textbf{Experiment Refinement}

Fisher Information analysis identifies which stimulation designs maximize parameter identifiability. Power analysis determines the minimum recording duration needed to detect individual differences. These computations guide protocol design before data collection begins, reducing wasted experimental effort.

\vspace{0.3cm}
\textbf{Additional Merits}

Simulation enables round-trip validation of clustering, ground-truth testing of phenotyping pipelines, and exploration of parameter space without animal use.
\end{frame}

%% ===========================================
%% TOOLING: MAGATFAIRY
%% ===========================================

\begin{frame}{MagatFairy Overview}
\centering
\includegraphics[height=0.55\textheight]{figures/magatfairy-cover.png}

\vspace{0.15cm}
\small MagatFairy converts MAGAT Analyzer experiments from MATLAB format to clean H5 files for Python workflows. The tool bundles the essential MAGAT core classes and uses the MATLAB Engine for Python to perform the conversion. A single command processes entire genotype directories containing multiple experiment sets.
\end{frame}

\begin{frame}{MagatFairy Pipeline}
\textbf{Input}

MAGAT Analyzer experiments stored as MATLAB .mat files in ESET directory structures. Each experiment contains track data, contours, derived quantities, and global measurements including LED timing.

\vspace{0.3cm}
\textbf{Conversion Process}

The MATLAB Engine loads each experiment using the DataManager class. Track-level data including positions, velocities, heading vectors, and behavioral states are extracted. Global quantities such as LED values and camera calibration are preserved. The ExportManager writes structured H5 files with standardized schema.

\vspace{0.3cm}
\textbf{Output}

Clean H5 files ready for Python analysis. Each file contains complete track arrays, derived quantities, LED timing at the ETI level, and camera calibration data. The standardized format enables consistent downstream processing across experiments.

\vspace{0.3cm}
\textbf{Usage} \quad Run \texttt{magatfairy convert auto /path/to/data} to process an entire genotype directory. The tool auto-detects data structure and handles batch conversion.
\end{frame}

\begin{frame}{MagatFairy in This Project}
\textbf{Role in Data Pipeline}

MagatFairy converted all 14 experiments comprising 701 larval tracks from the original MATLAB format to H5 files. The consolidated dataset used for kernel fitting and phenotyping analysis was assembled from these H5 outputs.

\vspace{0.3cm}
\textbf{Fields Extracted}

Track positions in millimeters, heading vectors, velocity components, SpeedRunVel, behavioral state flags including is\_reorientation and is\_run, LED state at each frame, and experiment timing. These fields feed directly into the hazard model.

\vspace{0.3cm}
\textbf{Going Forward}

New experiments can be processed with the same pipeline to ensure consistent data format. The H5 schema is documented at \texttt{docs/field-mapping.md}. Validation scripts verify that derived quantities match MATLAB reference implementations.

\vspace{0.3cm}
\textbf{Repository} \quad \texttt{github.com/GilRaitses/magatfairy}
\end{frame}

%% ===========================================
%% TOOLING: RETROVIBEZ
%% ===========================================

\begin{frame}{RetroVibez Overview}
\centering
\includegraphics[height=0.55\textheight]{figures/retrovibez-cover.png}

\vspace{0.15cm}
\small RetroVibez is an automated pipeline for detecting and analyzing reverse crawling behavior in \textit{Drosophila} larvae. It implements the reversal detection methods from Mason Klein's work and generates structured reports using Quarto for PDF and HTML output.
\end{frame}

\begin{frame}{RetroVibez Pipeline}
\textbf{Stage 1: MATLAB Analysis}

Headless MATLAB execution computes SpeedRunVel from heading and velocity vectors. Reversal events are detected when SpeedRunVel remains negative for at least 3 seconds. Results are saved as track-level H5 files.

\vspace{0.3cm}
\textbf{Stage 2: Figure Generation}

Parallel Python processing generates trajectory plots with speed-colored paths and reversals marked in purple. Dot product time series show the heading-velocity relationship. Close-up plots highlight individual reversal events.

\vspace{0.3cm}
\textbf{Stage 3: QMD Report}

A Quarto document is auto-generated from the analysis results. All figures are embedded with captions. Summary statistics are computed and formatted as tables.

\vspace{0.3cm}
\textbf{Stage 4: Rendering}

Quarto renders the QMD to both PDF and HTML formats. The PDF uses TinyTeX for clean typography. The HTML version enables interactive viewing.
\end{frame}

\begin{frame}{RetroVibez in This Project}
\textbf{Attribution}

RetroVibez implements the reverse crawling detection algorithm described in Klein et al. 2015. The core detection uses SpeedRunVel computed as the dot product of heading and velocity vectors. Negative values indicate backward movement.

\vspace{0.3cm}
\textbf{Role in Analysis}

Reverse crawl events were detected and quantified for data quality assessment. The Klein run table uses reversal boundaries for run segmentation. The detection algorithm is bundled within the MATLAB analysis script at \texttt{matlab/mason\_analysis.m}.

\vspace{0.3cm}
\textbf{Report Generation}

RetroVibez generates standardized analysis reports for each experiment. These reports document reversal counts, durations, and spatial distributions. The Quarto-based workflow enables reproducible report generation from raw data.

\vspace{0.3cm}
\textbf{Going Forward}

New experiments can be processed through the same pipeline. Reports are generated automatically with consistent formatting. The modular design allows extension to additional behavioral metrics.

\vspace{0.3cm}
\textbf{Repository} \quad \texttt{github.com/GilRaitses/retrovibez}
\end{frame}

%% ==================================================
%% SUPPLEMENTAL SLIDES
%% ==================================================

\appendix

\begin{frame}{Supplemental Materials}
\centering
\vspace{1cm}
{\Large \textbf{Appendix}}

\vspace{1cm}
Additional figures and analyses supporting the main presentation.

\vspace{0.5cm}
Organized chronologically by analysis stage.
\end{frame}

%% --- Data and Population ---

\begin{frame}{S1. Population-Level Data Summary}
\centering
\includegraphics[height=0.65\textheight]{../../figures/population_eda.png}

\vspace{0.15cm}
\small The dataset comprises 14 experiments with 701 larval tracks across four stimulation conditions. Track completeness analysis shows 19\% of tracks meet all quality thresholds for kernel fitting. Kernel timescales vary 3.9-fold across conditions, with the fast timescale tau1 ranging from 0.3 to 1.2 seconds. The intensity manipulation produces the largest effect size at g=2.4, exceeding the threshold for large effects. Mean R-squared values remain above 0.9 for all conditions except 50-250 Cycling, which shows reduced model fit at R-squared 0.73.
\end{frame}

\begin{frame}{S2. Early vs Late Habituation}
\centering
\includegraphics[height=0.65\textheight]{../../figures/figure_habituation_early_late.png}

\vspace{0.15cm}
\small Turn fraction increases substantially from early pulses 0-2 to late pulses 15-17 across all four experimental conditions. The 0-250 Constant condition shows the strongest habituation effect, rising from 44\% to 77\% turn fraction. All conditions display the same pattern of increased turning in later pulses, confirming that habituation develops progressively throughout the stimulation protocol. The cycling conditions show similar magnitude increases despite their more complex temporal structure.
\end{frame}

%% --- Model Fitting and Validation ---

\begin{frame}{S3. PSTH to Kernel Fitting}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig3_psth_kernel_v2.pdf}

\vspace{0.15cm}
\small Panel A shows the empirical peri-stimulus time histogram computed by binning reorientation events relative to LED onset. Panel B displays the fitted gamma-difference kernel with tau1 at 2.5 seconds indicating peak suppression timing. Panel C demonstrates how the Bernoulli process converts kernel values to event probabilities. The fitted kernel captures the empirical pattern of initial excitation followed by sustained suppression.
\end{frame}

\begin{frame}{S4. Posterior Predictive Checks}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig6_posterior_predictive.pdf}

\vspace{0.15cm}
\small Posterior predictive checks evaluate whether the fitted model generates data consistent with observations. Panel A shows pass rates for three metrics at event count 53.6\%, mean inter-stimulus interval 53.6\%, and PSTH shape at only 4.4\%. Panel B summarizes overall model adequacy with 37.2\% of simulated datasets passing all checks. The low PSTH shape pass rate indicates the model captures event timing but not the detailed temporal structure of individual responses.
\end{frame}

%% --- Trajectories and Simulation ---

\begin{frame}{S5. Simulated Larval Trajectories}
\centering
\includegraphics[height=0.65\textheight]{../../figures/figure3_trajectories.png}

\vspace{0.15cm}
\small Three example simulated trajectories demonstrate the stochastic Bernoulli point process generating reorientation events. Track 1 shows 39 events at 2.0 per minute, Track 2 shows 24 events at 1.2 per minute, and Track 3 shows 56 events at 2.8 per minute. Red markers indicate turn locations along the movement path. Yellow shading in the lower panels shows LED-ON periods. Event timing follows the fitted kernel with higher probability during LED-ON suppression windows.
\end{frame}

%% --- Factorial Design ---

\begin{frame}{S6. Factorial Design Analysis}
\centering
\includegraphics[height=0.65\textheight]{../../figures/figure5_factorial.png}

\vspace{0.15cm}
\small The 2x2 factorial design manipulates intensity step from 0 to 250 versus 50 to 250 PWM and background pattern constant versus cycling. Panel A shows suppression amplitude across conditions with the 0-250 Cycling condition producing the strongest suppression at 1.16. Panel B displays coefficient estimates with 95\% confidence intervals. Intensity modulation produces a significant negative effect on alpha, indicating faster suppression onset. The cycling-by-intensity interaction reaches statistical significance at p less than 0.05.
\end{frame}

\begin{frame}{S7. Validation Journey}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig1_validation_journey_v2.pdf}

\vspace{0.15cm}
\small The validation journey traces the progression from apparent phenotypes to continuous variation. Panel A shows initial clustering with silhouette 0.54 and 99.6\% classification accuracy suggesting four distinct phenotypes. Panel B reveals that round-trip validation fails with ARI below 0.2 for all cluster numbers. Panel C shows the method agreement matrix with cross-method ARI values below 0.3 indicating each method produces different clusters. Panel D identifies only 8.6\% of tracks as genuine outliers, with the remaining 91.4\% showing variation indistinguishable from measurement noise.
\end{frame}

%% --- Design Optimization ---

\begin{frame}{S8. Design Comparison Summary}
\centering
\includegraphics[height=0.65\textheight]{../figures/fig_design_comparison_summary.pdf}

\vspace{0.15cm}
\small Panel A compares event yield across stimulation designs with the current continuous protocol producing only 1.9 events per track. Burst stimulation with ten 0.5-second pulses increases yield 8-fold to 14.9 events. Panel B shows estimation error reduction with burst design achieving 3-fold lower RMSE at 0.036 seconds versus 0.108 for continuous. Panel C plots Fisher Information per event against event yield, demonstrating that burst design maximizes both metrics. The recommended protocol change would substantially improve individual phenotyping feasibility.
\end{frame}

\end{document}

